# Show line parameters
legend(x='bottomright',
legend=c(paste('Slope =', round(line_ret$params[1], digits=3)),
paste('VOffset =', round(line_ret$params[2], digits=3)),
paste('SD =', round(line_ret$params[3], digits=3)),
paste('Fit =', round(line_ret$fit_measure, digits=3))),
bty='n')
if (save_trial_plots)
dev.off()
# Plot reformatted data ----------------------
if (save_trial_plots)
tiff(file = paste(fa_dir, '/Trial_Plots/Reform_',
gsub('.asc', '', gsub('/', '_', sub_file)), '_', t, '.tiff', sep=""),
width = 4267, height = 3200, units = "px", res = 800, pointsize=6)
if (show_image) {
# If we're drawing an image
plot(t_image,
main='Reformatted Fixations',
xlab='x', ylab='New y',
xlim=c(0, t_image_width), ylim=c(t_image_height, 0))
axis(1)
axis(2)
} else {
# Blank plot
# Reverse y-limits so 0 at top
plot(1, type='n',
main='Reformatted Fixations',
xlab='x', ylab='New y',
xlim=c(x_min, x_max), ylim=c(y_max, y_min))
}
# The fixations
for (i in 1:n_lines) {
cat <- cats_keep == i
# Alternate category colors
if (i%%2 == 1)
col = 'black'
else
col = 'green'
points(fix_data_keep$x[cat], fix_data_keep$y_new[cat],
cex=fix_data_keep$pt_size[cat], col=col, pch=1)
}
# Show desired lines
for (i in 1:n_lines)
lines(c(start_pts[i,1], x_max),
c(start_pts[i,2], start_pts[i,2]),
col='grey')
# Duration scale information
legend(x='bottomleft',
legend=c(paste(dur_five_num[1], 'ms'),
paste(dur_five_num[2], 'ms'),
paste(dur_five_num[3], 'ms'),
paste(dur_five_num[4], 'ms'),
paste(dur_five_num[5], 'ms')),
pch=c(1, 1),
pt.cex=c(m*(dur_five_num[1] - dur_five_num[1]) + pt_size_min,
m*(dur_five_num[2] - dur_five_num[1]) + pt_size_min,
m*(dur_five_num[3] - dur_five_num[1]) + pt_size_min,
m*(dur_five_num[4] - dur_five_num[1]) + pt_size_min,
m*(dur_five_num[5] - dur_five_num[1]) + pt_size_min),
col=c('black', 'black'),
bty='n')
mtext(paste('File: ', sub_file, ', Trial: ', t, sep=''), outer=TRUE)
if (save_trial_plots)
dev.off()
}
##############################
# save_summary
##############################
save_summary <- function(line_ret, sub_file, out_file, n_trials) {
trial_list <- 1:n_trials
for (t in trial_list)
{
slope <- line_ret[[t]]$params[1]
voffset <- line_ret[[t]]$params[2]
sd <- line_ret[[t]]$params[3]
fit <- line_ret[[t]]$fit_measure
n_total_fix <- nrow(line_ret[[t]]$fix_data)
count_table <- table(line_ret[[t]]$fix_data$type)
n_keep <- length(line_ret[[t]]$fix_data$type[line_ret[[t]]$fix_data$type == 'keep'])
n_oob <- length(line_ret[[t]]$fix_data$type[line_ret[[t]]$fix_data$type == 'oob'])
n_amb <- length(line_ret[[t]]$fix_data$type[line_ret[[t]]$fix_data$type == 'amb'])
n_den <- length(line_ret[[t]]$fix_data$type[line_ret[[t]]$fix_data$type == 'den'])
n_nit <- length(line_ret[[t]]$fix_data$type[line_ret[[t]]$fix_data$type == 'nit'])
n_part <- length(line_ret[[t]]$fix_data$type[line_ret[[t]]$fix_data$type == 'part'])
cat(paste(sub_file, t, slope, voffset, sd, fit, n_total_fix, n_keep,
n_oob, n_amb, n_den, n_nit, n_part, '\n',
sep=' '),
file=out_file)
}
}
write_asc_file <- function(line_ret, orig_asc_file_name, n_trials, fa_dir, start_flag, asc_data) {
# Name and open the new asc file
# fa = (f)ix_(a)lign
# Check if directory exists, if not, make
if (!file.exists(fa_dir))
dir.create(fa_dir)
# Make the file name
new_asc_file_name <- strsplit(orig_asc_file_name, '/')
new_asc_file_name <- new_asc_file_name[[1]][length(new_asc_file_name[[1]])]
new_asc_file_name <- gsub('.asc', '_fa.asc', new_asc_file_name)
new_asc_file_name <- paste(fa_dir, '/', new_asc_file_name, sep='')
out_file <- file(new_asc_file_name, 'w')
# Read in the file
f <- readLines(orig_asc_file_name)
# Find all of the EFIX lines after start_flag, put into 1 vector
trial_id_start <- asc_data$trial_id_start
trial_start <- asc_data$trial_start
trial_end <- asc_data$trial_end
efix_lines <- numeric(0)
trial_list <- 1:n_trials
for (t in trial_list) {
trial_data  <- f[trial_id_start[t]:trial_end[t]]
trial_end_fix <- which(grepl('EFIX', trial_data))
efix_lines <- append(efix_lines, trial_end_fix + trial_id_start[t] - 1)
}
# Make a vector of all of the y-values in line_ret
line_ret_y_vals <- numeric(0)
trial_list <- 1:n_trials
for (t in trial_list) {
# Get a single trial of data
line_ret_trial <- line_ret[[t]]
# Mark the y-values for the deleted fixations
line_ret_trial$fix_data$y_new[line_ret_trial$fix_data$type == 'nit'] <- -1000
line_ret_trial$fix_data$y_new[line_ret_trial$fix_data$type == 'part'] <- -1001
line_ret_trial$fix_data$y_new[line_ret_trial$fix_data$type == 'oob'] <- -1002
line_ret_trial$fix_data$y_new[line_ret_trial$fix_data$type == 'amb'] <- -1003
line_ret_trial$fix_data$y_new[line_ret_trial$fix_data$type == 'den'] <- -1004
# Add the y-values onto the end of the vector
line_ret_y_vals <- append(line_ret_y_vals, line_ret_trial$fix_data$y_new)
}
# Go through each fixation
k <- 1
for	(i in efix_lines) {
# Parse out the fixation
fix_data <- gsub('\\s+', ' ', f[i])
fix_data <- strsplit(fix_data, ' ')
# What is the next reformatted y-coordinate
next_y <- line_ret_y_vals[k]
# Change y-coordinate
fix_data[[1]][7] <- next_y
# Overwrite the original line
f[i] <- paste(fix_data[[1]], sep='', collapse='   ')
k <- k + 1
}
# Write the file
#writeLines(f, out_file)
writeLines(f, out_file, sep="\r\n") # Thanks to Brian Dillon for this suggestion
# Close the file
close(out_file)
}
# Selecting Files, x-y Bounds and Start Points
numbers <- c(1:23,
# 24 - replacement has 63 rows, data has 62
25:26,
# 27 - replacement has 56 rows, data has 55
28:34,
# 35 - Error in trial_id_start[t]:trial_end[t] : NA/NaN argument
36:51,
# 52 - Error in trial_id_start[t]:trial_end[t] : NA/NaN argument
# ((72 x trialid, 67 x trial_result/trial ok, 5 x trial aborted))
53:66,
# 67 - replacement has 12 rows, data has 11
# ((68 x trialid, 67 x trial_result/trial ok, 1 x trial aborted))
68:83,
# 84 - replacement has 101 rows, data has 100
85:99)
file <- rep("DBP", length(numbers))
numbers <- sprintf("%02d", numbers)
asc_files <- paste0("FixAlign/Detecting_script_error_and_lst", "w_", file, numbers, ".asc")
xy_bounds <- NULL
start_pts <- rbind(c(200, 324), c(200, 396), c(200, 468), c(200, 540), c(200, 612), c(200, 684))
fix_align(start_pts = start_pts,
asc_files = asc_files,
xy_bounds = xy_bounds,
fa_dir="/Users/duncan/Documents/R analyses/Prediction_Integration/Prediction_Integration/FixAlign")
file <- rep("w_DBP", length(numbers))
numbers <- sprintf("%02d", numbers)
asc_files <- paste0("FixAlign/Detecting_script_error_and_lst/", "w_", file, numbers, ".asc")
xy_bounds <- NULL
start_pts <- rbind(c(200, 324), c(200, 396), c(200, 468), c(200, 540), c(200, 612), c(200, 684))
fix_align(start_pts = start_pts,
asc_files = asc_files,
xy_bounds = xy_bounds,
fa_dir="/Users/duncan/Documents/R analyses/Prediction_Integration/Prediction_Integration/FixAlign")
file <- rep("w_DBP", length(numbers))
numbers <- sprintf("%02d", numbers)
file <- rep("DBP", length(numbers))
numbers <- sprintf("%02d", numbers)
library(reticulate)
setwd("FixAlign")
source_python("Robodoc.py")
library(reticulate)
setwd("FixAlign")
library(reticulate)
setwd("FA_tidy")
source_python("Robodoc.py")
parmeters.txt
library(reticulate)
setwd("FA_tidy")
setwd("FA_tidy")
library(reticulate)
setwd("FA_tidy")
setwd("/Users/elizabethle-luan/Desktop/Duncans_Grant/FixAlign")
source_python("Robodoc.py")
source_python("Robodoc.py")
library(reticulate)
setwd("/Users/elizabethle-luan/Desktop/Duncans_Grant/FixAlign")
source_python("Robodoc.py")
source_python("make_cnt.py")
library(lme4)
install.packages('packrat::init()')
install.packages("packrat")
library(packrat)
library('packrat')
install.packages('IRkernel')
View(install.packages())
install.packages('IRkernel')
View(install.packages())
R CMD INSALL --no-lock <IRkernel>
#.libPaths("C:Program Files/R/R-3.5/library")
#devtools::install_github("crsh/papaja")
library(Matrix)
library(lme4)
library(lmerTest)
library(emmeans)
install.packages("emmeans")
library(emmeans)
library(stats)
library(fitdistrplus)
library(tidyverse)
library(buildmer)
library(performance)
library(see)
install.packages("buildmer")
#.libPaths("C:Program Files/R/R-3.5/library")
#devtools::install_github("crsh/papaja")
library(Matrix)
library(lme4)
library(lmerTest)
library(emmeans)
install.packages(emmeans)
install.packages("emmeans")
install.packages("emmeans")
rm -rf \Users\eliza\Documents\R\win-library\4.0/00LOCK
rm -rf Users\eliza\Documents\R\win-library\4.0/00LOCK
#.libPaths("C:Program Files/R/R-3.5/library")
#devtools::install_github("crsh/papaja")
library(Matrix)
library(lme4)
library(lmerTest)
library(emmeans)
library(stats)
library(fitdistrplus)
library(tidyverse)
library(buildmer)
library(performance)
library(see)
library(sjPlot)
#Set seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
library(readr)
FP_ED_batch_corr <- read_csv("Manual_tidy_analysis/First_pass/FP_ED/FP_ED_batch_corr.csv")
FP_ED_batch_error <- read_csv("Manual_tidy_analysis/First_pass/FP_ED/FP_ED_batch_error.csv")
#Rename the participant numbers in the batches back to their original participant numbers.
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 54] <-"84"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 53] <-"83"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 52] <-"82"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 51] <-"81"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 50] <-"80"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 49] <-"79"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 48] <-"78"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 47] <-"77"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 46] <-"76"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 45] <-"75"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 44] <-"74"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 43] <-"73"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 42] <-"72"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 41] <-"71"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 40] <-"70"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 39] <-"69"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 38] <-"68"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 37] <-"67"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 36] <-"66"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 35] <-"64"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 34] <-"62"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 33] <-"60"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 32] <-"58"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 31] <-"56"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 30] <-"54"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 29] <-"52"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 28] <-"50"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 27] <-"48"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 26] <-"46"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 25] <-"44"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 24] <-"43"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 23] <-"42"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 22] <-"40"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 21] <-"39"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 20] <-"38"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 19] <-"36"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 18] <-"35"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 17] <-"34"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 16] <-"32"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 15] <-"30"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 14] <-"28"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 13] <-"26"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 12] <-"24"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 11] <-"22"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 10] <-"20"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 9] <-"18"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 8] <-"16"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 7] <-"14"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 6] <-"12"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 5] <-"10"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 4] <-"8"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 3] <-"6"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 2] <-"4"
FP_ED_batch_corr$subj[FP_ED_batch_corr$subj == 1] <-"2"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 31] <-"65"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 30] <-"63"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 29] <-"61"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 28] <-"59"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 27] <-"57"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 26] <-"55"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 25] <-"53"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 24] <-"51"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 23] <-"49"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 22] <-"47"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 21] <-"45"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 20] <-"41"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 19] <-"37"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 18] <-"35"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 17] <-"33"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 16] <-"31"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 15] <-"29"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 14] <-"27"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 13] <-"25"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 12] <-"23"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 11] <-"21"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 10] <-"19"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 9] <-"17"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 8] <-"15"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 7] <-"13"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 6] <-"11"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 5] <-"9"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 4] <-"7"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 3] <-"5"
FP_ED_batch_error$subj[FP_ED_batch_error$subj == 2] <-"3"
#Check the subject numbers have been redefined correctly
#View(FP_ED_batch_corr)
#View(FP_ED_batch_error)
#Let's combine the data
all_data <- rbind(FP_ED_batch_corr, FP_ED_batch_error)
#make subj a factor
all_data$subj <- as.factor(all_data$subj)
#Import Individual difference measures
All_IDs <- read_csv("Other_data_and_information/All_IDs.csv")
#View(All_IDs)
# Rename Participabt in ID_measures to subj to be the same as current data set
All_IDs <- rename(All_IDs, subj = Participant)
All_IDs$subj <- as.factor(All_IDs$subj)
# Add the ID's to the data frame
all_data_join <- inner_join(all_data, All_IDs, by = "subj")
#view(all_data_join)
# Assign condition labels, 1 = prediction facilitated, 2 = prediction unfacilitated
#(this will make it easier to interpret)
all_data_join$cond <- recode(all_data_join$cond, "1" = "facilitated", "2" = "unfacilitated")
#Let's have a look at region 4
#set condition as a factor
all_data_join$cond <- as.factor(all_data_join$cond)
# Throw away zeroes
all_data_join <- all_data_join %>% filter(R4 != 0)
#Let's have a look at region 4
#set condition as a factor
all_data_join$cond <- as.factor(all_data_join$cond)
# Throw away zeroes
all_data_join <- all_data_join %>% filter(R4 != 0)
#Visualisation
all_data_join %>%
ggplot(aes(x = cond, y = R4, colour = cond)) + ggtitle("First Pass for Critical Region: Question") +
labs(y = "Reading time in ms.", x = "Prediction") +
geom_violin() +
geom_jitter(alpha = .2, width = .1) +
stat_summary(fun.data = "mean_cl_boot", colour = "black") +
guides(colour = FALSE)
#Descriptives
all_data_join %>%
group_by(cond) %>%
summarise(mean(R4), sd(R4))
# Model assuming normality of residuals maximal structure
#model.nullR4 <- lmer(R4 ~ (1 + cond | subj) + (1 + cond | item), all_data_join)
modelR4 <- lmer(R4 ~ cond + (1 + cond | subj) + (1 + cond | item), all_data_join)
summary(modelR4)
#All the data for this model looks pretty normal.
check_model(modelR4)
#Step 1: Scale the ID measures...
all_data_join$SRS_total_score_t <- scale(all_data_join$SRS_total_score_t)
all_data_join$EQ <- scale(all_data_join$EQ)
all_data_join$Total_reading_cluster <- scale(all_data_join$Total_reading_cluster)
all_data_join$Total_RAN <- scale(all_data_join$Total_RAN)
all_data_join$"WI _RPI" <- scale(all_data_join$"WI _RPI")
# Model including covariates
model_alldatacov_R4 <- lmer(R4 ~ SRS_total_score_t + EQ + Total_reading_cluster + Total_RAN + cond + (1 | subj) +  (1 + cond | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R4)
# Getting our Summary of Mixed Models as a table using the sjPlot package.
#Nakagawa S, Johnson P, Schielzeth H (2017)
#The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisted and expanded.
#J. R. Soc. Interface 14. doi: 10.1098/rsif.2017.0213
tab_model(model_alldatacov_R4, p.val = "kr", show.df = TRUE)
summary(model_alldatacov_R4)
model_alldatacov_R4_noRAN <- lmer(R4 ~ SRS_total_score_t + EQ + Total_reading_cluster + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R4_noRAN)
model_alldatacov_R4_RAN_int <- lmer(R4 ~ SRS_total_score_t + EQ + Total_reading_cluster + Total_RAN + cond + cond:Total_RAN + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R4_RAN_int)
summary(model_alldatacov_R4)
model_alldatacov_R4_noRAN <- lmer(R4 ~ SRS_total_score_t + EQ + Total_reading_cluster + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R4_noRAN)
model_alldatacov_R4_RAN_int <- lmer(R4 ~ SRS_total_score_t + EQ + Total_reading_cluster + Total_RAN + cond + cond:Total_RAN + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R4_RAN_int)
#anova(model_alldatacov_R4_null, model_alldatacov_R4)
check_model(model_alldatacov_R4)
ranef(model_alldatacov_R4)
library(Hmisc)
#Measuring Correlations
EQscore <- all_data_join %>% group_by(subj) %>% summarise(mean = mean(EQ)) %>% pull(mean)
SRS2 <- all_data_join %>% group_by(subj) %>% summarise(mean = mean(SRS_total_score_t)) %>% pull(mean)
WRMT <- all_data_join %>% group_by(subj) %>% summarise(mean = mean(Total_reading_cluster)) %>% pull(mean)
RAN <- all_data_join %>% group_by(subj) %>% summarise(mean = mean(Total_RAN)) %>% pull(mean)
rcorr(EQscore, SRS2)
rcorr(EQscore, WRMT)
rcorr(EQscore, RAN)
rcorr(SRS2, WRMT)
rcorr(SRS2, RAN)
rcorr(WRMT, RAN)
#set condition as a factor
all_data_join$cond <- as.factor(all_data_join$cond)
# Throw away zeroes
all_data_join <- all_data_join %>% filter(R5 != 0)
#set condition as a factor
all_data_join$cond <- as.factor(all_data_join$cond)
# Throw away zeroes
all_data_join <- all_data_join %>% filter(R5 != 0)
#Visualisation
all_data_join %>%
ggplot(aes(x = cond, y = R5, colour = cond)) + ggtitle("First Pass for Post-Critical Region: Reply") +
labs(y = "Reading time in ms.", x = "Prediction") +
geom_violin() +
geom_jitter(alpha = .2, width = .1) +
stat_summary(fun.data = "mean_cl_boot", colour = "black") +
guides(colour = FALSE)
#Descriptives
all_data_join %>%
group_by(cond) %>%
summarise(mean(R5), sd(R5))
# Model assuming normality of residuals maximal structure
#model.nullR5 <- lmer(R5 ~ (1 + cond | subj) + (1 + cond | item), all_data_join)
modelR5 <- lmer(R5 ~ cond + (1 + cond | subj) + (1 + cond | item), all_data_join)
summary(modelR5)
#All the data for this model looks pretty normal.
check_model(modelR5)
#qqnorm(residuals(modelR5))
#qqline(residuals(modelR5))
descdist(all_data_join$R5)
#Step 1: Scale the ID measures...
all_data_join$SRS_total_score_t <- scale(all_data_join$SRS_total_score_t)
all_data_join$EQ <- scale(all_data_join$EQ)
all_data_join$Total_reading_cluster <- scale(all_data_join$Total_reading_cluster)
all_data_join$Total_RAN <- scale(all_data_join$Total_RAN)
all_data_join$"WI _RPI" <- scale(all_data_join$"WI _RPI")
# Model including covariates
model_alldatacov_R5 <- lmer(R5 ~ SRS_total_score_t + EQ + Total_reading_cluster + Total_RAN + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R5)
model_alldatacov_R5_noRAN <- lmer(R5 ~ SRS_total_score_t + EQ + Total_reading_cluster + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
model_alldatacov_R5_noRAN <- lmer(R5 ~ SRS_total_score_t + EQ + Total_reading_cluster + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R5_noRAN)
model_alldatacov_R5_RAN_int <- lmer(R5 ~ SRS_total_score_t + EQ + Total_reading_cluster + Total_RAN + cond + cond:Total_RAN + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R5_RAN_int)
#Step 1: Scale the ID measures...
all_data_join$SRS_total_score_t <- scale(all_data_join$SRS_total_score_t)
all_data_join$EQ <- scale(all_data_join$EQ)
all_data_join$Total_reading_cluster <- scale(all_data_join$Total_reading_cluster)
all_data_join$Total_RAN <- scale(all_data_join$Total_RAN)
all_data_join$"WI _RPI" <- scale(all_data_join$"WI _RPI")
#set condition as a factor
all_data_join$cond <- as.factor(all_data_join$cond)
# Throw away zeroes
all_data_join <- all_data_join %>% filter(R3 != 0)
#set condition as a factor
all_data_join$cond <- as.factor(all_data_join$cond)
# Throw away zeroes
all_data_join <- all_data_join %>% filter(R3 != 0)
#Visualisation
all_data_join %>%
ggplot(aes(x = cond, y = R3, colour = cond)) + ggtitle("First Pass for Post-Critical Region: Prediction") +
labs(y = "Reading time in ms.", x = "Prediction") +
geom_violin() +
geom_jitter(alpha = .2, width = .1) +
stat_summary(fun.data = "mean_cl_boot", colour = "black") +
guides(colour = FALSE)
#Step 1: Scale the ID measures...
all_data_join$SRS_total_score_t <- scale(all_data_join$SRS_total_score_t)
all_data_join$EQ <- scale(all_data_join$EQ)
all_data_join$Total_reading_cluster <- scale(all_data_join$Total_reading_cluster)
all_data_join$Total_RAN <- scale(all_data_join$Total_RAN)
all_data_join$"WI _RPI" <- scale(all_data_join$"WI _RPI")
# Model including covariates
model_alldatacov_R3 <- lmer(R3 ~ SRS_total_score_t + EQ + Total_reading_cluster + Total_RAN + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
summary(model_alldatacov_R3)
#anova(model_alldatacov_R5_null, model_alldatacov_R5)
check_model(model_alldatacov_R3)
model_alldatacov_R3_noRAN <- lmer(R3 ~ SRS_total_score_t + EQ + Total_reading_cluster + cond + (1 | subj) +  (1 | item) , data = all_data_join, REML = TRUE)
